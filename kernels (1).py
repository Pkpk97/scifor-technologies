# -*- coding: utf-8 -*-
"""kernels.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YkqvLTc_utCA3Flw-dc0CfAAto3K7HKP
"""



"""Explain various types of  Kernels with respect to the formula
Kernel Function is a method used to take data as input and transform it into the required form of processing data. “Kernel” is used due to a set of mathematical functions used in Support Vector Machine providing the window to manipulate the data. So, Kernel Function generally transforms the training set of data so that a non-linear decision surface is able to transform to a linear equation in a higher number of dimension spaces. Basically, It returns the inner product between two points in a standard feature dimension.
Gaussian Kernel: It is used to perform transformation when there is no prior knowledge about data.
K (x, y) = e ^ - (\frac{||x - y||^2} {2 \sigma^2})


Gaussian Kernel Radial Basis Function (RBF): Same as above kernel function, adding radial basis method to improve the transformation.

K (x, y) = e ^ - (\gamma{||x - y||^2})


Sigmoid Kernel: this function is equivalent to a two-layer, perceptron model of the neural network, which is used as an activation function for artificial neurons.
K (x, y) = tanh (\gamma.{x^T y}+{r})

Polynomial Kernel: It represents the similarity of vectors in the training set of data in a feature space over polynomials of the original variables used in the kernel.
K (x, y) = tanh (\gamma.{x^T y}+{r})^d, \gamma>0




"""